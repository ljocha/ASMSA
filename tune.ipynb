{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ASMSA: Tune AAE model hyperparameters\n",
    "\n",
    "**Previous step**\n",
    "- [prepare.ipynb](prepare.ipynb): Download and sanity check input files\n",
    "\n",
    "**Next steps**\n",
    "- [train.ipynb](train.ipynb): Use results of previous tuning in more thorough training\n",
    "- [md.ipynb](md.ipynb): Use a trained model in MD simulation with Gromacs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd villin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threads = 2\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS']=str(threads)\n",
    "import tensorflow as tf\n",
    "\n",
    "# PyTorch favours OMP_NUM_THREADS in environment\n",
    "import torch\n",
    "\n",
    "# Tensorflow needs explicit cofig calls\n",
    "tf.config.threading.set_inter_op_parallelism_threads(threads)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from tensorflow import keras\n",
    "import keras_tuner\n",
    "import asmsa\n",
    "from datetime import datetime\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Input files\n",
    "\n",
    "All input files are prepared (up- or downloaded) in [prepare.ipynb](prepare.ipynb). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exec(open('inputs-des.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load train dataset\n",
    "X_train = tf.data.Dataset.load('../Thermal-unfolding/datasets/intcoords/train')\n",
    "X_train_np = np.stack(list(X_train))\n",
    "X_train_np = X_train_np[:int(0.5*len(X_train_np))]\n",
    "\n",
    "# load validation dataset\n",
    "X_validate = tf.data.Dataset.load('../Thermal-unfolding/datasets/intcoords/validate')\n",
    "X_validate_np = np.stack(list(X_validate))\n",
    "\n",
    "X_train_np.shape, X_validate_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Hyperparameter definition\n",
    "Specify hyperparameter ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_hp = {\n",
    "    'activation' : ['gelu','selu'],\n",
    "    'ae_neuron_number_seed' : [32,64,96,128],\n",
    "    'disc_neuron_number_seed' : [32,64,96],\n",
    "    'ae_number_of_layers' : [2,3,5],\n",
    "    'disc_number_of_layers' : [2,3,5],\n",
    "    'batch_size' : [64,128],\n",
    "    'optimizer' : ['Adam'],\n",
    "    'learning_rate' : 0.0002,\n",
    "    'ae_loss_fn' : ['MeanSquaredError'],\n",
    "    'disc_loss_fn' : ['BinaryCrossentropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Sequential hyperparameter tuning\n",
    "\n",
    "This is robust, it does not require Kubernetes environment for additional job submission but GPU is strongly recommended in the notebook itself to get reasonable speed, not requiring the following (currently broken) parallel tuning section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Just testing numbers of epochs and hyperparameter setting trials\n",
    "# Don't expect anything meaningful\n",
    "trials=50\n",
    "epochs=30\n",
    "\n",
    "# Set RESULTS_DIR env variable for results of tuning\n",
    "os.environ['RESULTS_DIR'] = datetime.today().strftime(\"%m%d%Y-%H%M%S\")\n",
    "tuner = keras_tuner.RandomSearch(\n",
    "    max_trials=trials,\n",
    "    hypermodel=\n",
    "        asmsa.AAEHyperModel(\n",
    "            (X_validate_np.shape[1],),\n",
    "            hp=medium_hp,\n",
    "            prior=tfp.distributions.Normal(loc=0, scale=1)),\n",
    "    objective=keras_tuner.Objective(\"score\", direction=\"min\"),\n",
    "    directory=\"./results\",\n",
    "    project_name=\"Random\",\n",
    "    overwrite=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner.search(train=X_train_np,validation=X_validate_np,epochs=epochs,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from asmsa.tuning_analyzer import TuningAnalyzer\n",
    "\n",
    "# Create analyzer object that analyses results of tuning\n",
    "# By default it is the latest tuning, but can by choosen with tuning flag,\n",
    "#  e.g TuningAnalyzer(tuning='analysis/05092023-135249')\n",
    "analyzer = TuningAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get sorted hyperparameters by score, by default 10 best HP, for different number:\n",
    "#  analyzer.get_best_hp(num_trials=3)\n",
    "analyzer.get_best_hp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Matplotlib visualization - not recommended way, does not look that good and does not scale \n",
    "#  that well but at least the colors are consistent accross measures. After more work could look better\n",
    "# - By default visualizing best 10 trials\n",
    "# - Can specify only one specific trial... analyzer.visualize_tuning(trial='15d9fa928a7517004bcb28771bb6e5f17ad66dd7013c6aa1572a84773d91393c')\n",
    "# - Can specify number of best trials to be visualized... analyzer.visualize_tuning(num_trials=3)\n",
    "analyzer.visualize_tuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Recommended option via Tensorboard. This function populates TB event\n",
    "#  which can be viewed in native way via Tensorboard. \n",
    "# May not work in all Jupyterhub setups, though.\n",
    "\n",
    "# By default it chooses latest tuning and populates into its directory _TB, e.g: analysis/05092023-135249/_TB\n",
    "# - Can override directory where to populate... analyzer.populate_TB(out_dir='MyTBeventDir')\n",
    "# - Can choose only specific trials via list... analyzer.populate_TB(trials=['15d9fa928a7517004bcb28771bb6e5f17ad66dd7013c6aa1572a84773d91393c']),\n",
    "# - Can select how many best trials to be visualized... analyzer.populate_TB(num_trials=3)\n",
    "analyzer.populate_TB(num_trials=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Parallel hyperparameter tuning\n",
    "\n",
    "**BROKEN**, ignore the rest of this notebook for the time being"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finally, this is the real stuff\n",
    "# medium settings known to be working for trpcage\n",
    "\n",
    "epochs=15\n",
    "trials=3\n",
    "hp=medium_hp\n",
    "\n",
    "# testing only\n",
    "#epochs=8\n",
    "#trials=6\n",
    "#hp=tiny_hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of parallel workers, each runs a single trial at time\n",
    "# balance between resource availability and size of the problem\n",
    "# currently each slave runs on 4 cores and 4 GB RAM (hardcoded in src/asmsa/tunewrapper.py)\n",
    "\n",
    "slaves=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# XXX: Kubernetes magic: find out names of container image and volume\n",
    "# check the result, it can go wrong\n",
    "\n",
    "with open('IMAGE') as img:\n",
    "    image=img.read().rstrip()\n",
    "\n",
    "import re\n",
    "mnt=os.popen('mount | grep /home/jovyan').read()\n",
    "pvcid=re.search('pvc-[0-9a-z-]+',mnt).group(0)\n",
    "pvc=os.popen(f'kubectl get pvc | grep {pvcid} | cut -f1 -d\" \"').read().rstrip()\n",
    "\n",
    "print(f\"\"\"\\\n",
    "image: {image}\n",
    "volume: {pvc}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python wrapper around scripts that prepare and execute parellel Keras Tuner in Kubernetes\n",
    "from asmsa.tunewrapper import TuneWrapper\n",
    "\n",
    "wrapper = TuneWrapper(ds=X_validate_np,hp=hp,output=datetime.today().strftime(\"%m%d%Y-%H%M%S\"),epochs=epochs,trials=trials,pdb=conf,top=topol,xtc=traj,ndx=index, pvc=pvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Necessary but destructive cleanup before hyperparameter tuning\n",
    "\n",
    "# DON'T RUN THIS CELL BLINDLY\n",
    "# it kills any running processes including the workers, and it purges previous results\n",
    "\n",
    "!kubectl delete job/tuner\n",
    "!kill $(ps ax | grep tuning.py | awk '{print $1}')\n",
    "!rm -rf results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start the master (chief) of tuners in background\n",
    "# the computation takes rather long, this is a more robust approach then keeping it in the notebook\n",
    "\n",
    "wrapper.master_start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# therefore one should check the status ocassionally; it should show a tuning.py process running\n",
    "print(wrapper.master_status())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# spawn the requested number of workers as separate Kubernetes job with several pods \n",
    "# they receive work from \n",
    "\n",
    "wrapper.workers_start(num=slaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This status should show {slaves} number of pods, all of them start in Pending state, and follow through ContainerCreating \n",
    "# to Running, and Completed finally\n",
    "\n",
    "# This takes time, minutes to hours depending on size of the model, number of trials, and number of slaves\n",
    "# Run this cell repeatedly, waiting until all the pods are completed\n",
    "\n",
    "wrapper.workers_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Same steps for analysis as with serial tuning\n",
    "analyzer = TuningAnalyzer()\n",
    "analyzer.get_best_hp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can choose output dir for TB event this time\n",
    "out = 'dist_tuning'\n",
    "\n",
    "analyzer.populate_TB(out_dir=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Might need to kill previous tensorboard instance to change logdir\n",
    "!pkill -f 'tensorboard'\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir $out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
