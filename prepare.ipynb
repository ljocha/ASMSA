{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ASMSA: Prepare and check input files\n",
    "\n",
    "**Next steps**\n",
    "- [tune.ipynb](tune.ipynb): Perform initial hyperparameter tuning for this molecule\n",
    "- [train.ipynb](train.ipynb): Use results of previous tuning in more thorough training\n",
    "- [md.ipynb](md.ipynb): Use a trained model in MD simulation with Gromacs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd trpcage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoid TF to consume GPU memory\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "tf.config.list_logical_devices()\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoid TF to consume GPU memory\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "tf.config.list_logical_devices()\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import asmsa\n",
    "import os\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import gromacs as gmx\n",
    "import gromacs.fileformats as gf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Prepare input files\n",
    "\n",
    "Tryptophan cage files are downloaded in this section from our Google drive. \n",
    "\n",
    "This is for demonstration purpose, in real use the inputs should be placed here, and _conf, traj, topol, index_ variables set to their filenames names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input files\n",
    "base = 'trpcage'\n",
    "\n",
    "# input conformation, it should not contain hydrogens\n",
    "conf = base + '_correct.pdb'\n",
    "\n",
    "# input trajectory\n",
    "# atom numbering must be consistent with {conf}, no hydrogens as well\n",
    "\n",
    "traj = 'trpcage_red.xtc'\n",
    "\n",
    "# everything else is generated with pdb2gmx to make sure the files are consistent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "#### Density of additional internal coordinates\n",
    "\n",
    "In how many randomly sampled distances from all atom-to-atom one atom should appear in average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_density = 2 # integer in [1, n_atoms-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "topol = base + '.top'\n",
    "index = base + '.ndx'\n",
    "gro = base + '.gro'\n",
    "\n",
    "with open('inputs.py','w') as i:\n",
    "    i.write(f'''\n",
    "base = '{base}'\n",
    "conf = '{conf}'\n",
    "traj = '{traj}'\n",
    "topol = '{topol}'\n",
    "index = '{index}'\n",
    "gro = '{gro}'\n",
    "\n",
    "nb_density = {nb_density}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmx.pdb2gmx(f=conf, ignh=True,p=topol,n=index,o=gro,water='tip3p',ff='amber99sb-ildn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trajectory, it should report expected numbers of frames and atoms/residua\n",
    "\n",
    "tr = md.load(traj,top=conf)\n",
    "idx=tr[0].top.select(\"name CA\")\n",
    "\n",
    "# for trivial cases like Ala-Ala, where superposing on CAs fails\n",
    "#idx=tr[0].top.select(\"element != H\")\n",
    "\n",
    "tr.superpose(tr[0],atom_indices=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual check, all frames should look \"reasonable\"\n",
    "\n",
    "# Because of different conventions of numbering atoms in proteins,\n",
    "# PDB file {conf} and the trajectory {traj} can become inconsistent, and this would appear here \n",
    "# as rather weird shapes of the molecule\n",
    "\n",
    "import nglview as nv\n",
    "\n",
    "v = nv.show_mdtraj(tr)\n",
    "v.clear()\n",
    "v.add_representation(\"licorice\")\n",
    "#v.add_representation('ball+stick', selection='ZN2', radius=0.5, color=\"green\") no Zn :(\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Split datasets\n",
    "\n",
    "Split trajectory into 3 parts. Each part will represent training, validation and testing dataset respectively. The workflow is following:\n",
    "1. Shuffle configurations in trajectory\n",
    "2. Select proportions to divide the trajectory\n",
    "3. Divide the trajectory\n",
    "4. Compute RMSD between\n",
    "   * **train x validation** trajectory and filter similar structures in train trajectory\n",
    "   * **train x test** trajectory and filter similar structures in train trajectory\n",
    "   * **test x validation** trajectory and filter similar structures in test trajectory\n",
    "5. Transform into internal coordinates\n",
    "6. Save internal coordinates as datasets which can be loaded in **train.ipynb** and **tune.ipynb** notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the trajectory so the configurations are dispersed across all datasets\n",
    "np.random.shuffle(tr.xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - set proportions for train, validation and test datasets\n",
    "# - proportions must be equal to 1 when added together\n",
    "train = .7\n",
    "validation = .15\n",
    "test = .15\n",
    "\n",
    "assert train + validation + test == .9999999999999999 or 1\n",
    "\n",
    "tr_i = len(tr) * train\n",
    "X_train = tr.slice(slice(0,int(tr_i)))\n",
    "\n",
    "va_i = len(tr) * validation\n",
    "X_validate = tr.slice(slice(int(tr_i),int(tr_i)+int(va_i)))\n",
    "\n",
    "te_i = len(tr) * test\n",
    "X_test = tr.slice(slice(int(tr_i)+int(va_i),len(tr)))\n",
    "\n",
    "X_train.xyz.shape, X_validate.xyz.shape, X_test.xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.save_xtc('train.xtc')\n",
    "X_validate.save_xtc('validate.xtc')\n",
    "X_test.save_xtc('test.xtc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eventual recovery\n",
    "\n",
    "X_train = md.load_xtc('train.xtc',conf)\n",
    "X_validate = md.load_xtc('validate.xtc',conf)\n",
    "X_test = md.load_xtc('test.xtc',conf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "# Keep on calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get RMSD from train trajectory compared to validation trajectory\n",
    "gmx.select(s=conf,on='backbone.ndx',select='Backbone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmx.rms(s=conf,f='train.xtc',f2='validate.xtc',n='backbone.ndx',m='trainxval_rmsd.xpm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the RMDS matrix\n",
    "txv = gf.XPM('trainxval_rmsd.xpm')\n",
    "txv.array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# minima per row -- for each configuration in train, how far is the nearest one from validation\n",
    "txv_min = np.min(txv.array,axis=1)\n",
    "txv_min.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(txv_min,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop similar structures (to validation trajectory) in train trajectory to avoid dataset being biased\n",
    "txv_difference = 0.05\n",
    "\n",
    "train_tr = X_train[np.argwhere(txv_min > txv_difference).flat]\n",
    "train_tr.xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tr.save_xtc('tmp_train.xtc')\n",
    "gmx.rms(s=conf,f='tmp_train.xtc',f2='test.xtc',n='backbone.ndx',m='trainxtest_rmsd.xpm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = gf.XPM('trainxtest_rmsd.xpm')\n",
    "txt.array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_min = np.min(txt.array,axis=1)\n",
    "txt_min.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(txt_min,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... one more time with test trajectory & test x validation...\n",
    "txt_difference = 0.05\n",
    "\n",
    "x_train = train_tr[np.argwhere(txt_min > txt_difference).flat]\n",
    "x_train.save_xtc('x_train.xtc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test x validation\n",
    "gmx.rms(f='test.xtc',f2='validate.xtc',s=conf,n='backbone.ndx',m='testxvalidate_rmsd.xpm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "txv = gf.XPM('testxvalidate_rmsd.xpm')\n",
    "txv.array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "txv_min = np.min(txv.array,axis=1)\n",
    "txv_min.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(txv_min,bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... one more time with test trajectory & test x validation...\n",
    "txv_difference = 0.05\n",
    "\n",
    "x_test = X_test[np.argwhere(txv_min > txv_difference).flat]\n",
    "x_test.save_xtc('x_test.xtc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip thorough RMS\n",
    "! ln train.xtc x_train.xtc\n",
    "! ln test.xtc x_test.xtc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "# Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('inputs.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recovery\n",
    "\n",
    "x_train = md.load('x_train.xtc', top=conf)\n",
    "x_test = md.load('x_test.xtc', top=conf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "# Anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shapes of filtered trajectories that are to be used as datasets\n",
    "validate_tr = md.load('validate.xtc', top=conf)\n",
    "\n",
    "trajs = [x_train, validate_tr, x_test]\n",
    "x_train.xyz.shape, validate_tr.xyz.shape, x_test.xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshuffle the geometries to get frame last so that we can use vectorized calculations later on\n",
    "geoms = [ np.moveaxis(t.xyz,0,-1) for t in trajs]\n",
    "print ([ g.shape for g in geoms ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save geometries\n",
    "\n",
    "tf.data.Dataset.from_tensor_slices(geoms[0]).save('datasets/geoms/train')\n",
    "tf.data.Dataset.from_tensor_slices(geoms[1]).save('datasets/geoms/validate')\n",
    "tf.data.Dataset.from_tensor_slices(geoms[2]).save('datasets/geoms/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "# Internal coordinates computation\n",
    "\n",
    "Exercise the ASMSA library on your input. Just check everything appears to work.\n",
    "\n",
    "There are multiple options that can be combined:\n",
    "- use traditional internal coordinates (bond distances, angles, and dihedrals) or not\n",
    "- include additional distances between atoms that may not be bound to express protein folding state more directly\n",
    "   - dense (all-to-all) atom distances, feasible for very small peptides only\n",
    "   - sparse atom distances (only some pairs are chosen)\n",
    "   \n",
    "\n",
    "We save the computed internal coordinates for training, and a feature extraction model here, therefore everything in the other notebooks should work too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "## New - Traditional internal coordinates (all bond distances, angles, and torsions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# mol = asmsa.Molecule(conf,topol)\n",
    "\n",
    "# internal coordinates and sparse any-any atom distances (not restricted to bonds)\n",
    "# eventually, top (and index) can be left out to use sparse distances only\n",
    "\n",
    "sparse_dists = asmsa.NBDistancesSparse(geoms[0].shape[0], density=nb_density)\n",
    "mol=asmsa.Molecule(pdb=conf,top=topol,ndx=index,fms=[sparse_dists])\n",
    "\n",
    "# dense distances are feasible for very small (upto 5 residua) peptides only\n",
    "\n",
    "# dense_dists = asmsa.NBDistancesDense(geom.shape[0])\n",
    "# mol = asmsa.Molecule(pdb=conf,top=topol,ndx=index,fms=[dense_dists])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(+ mol.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "##### Alternative: only backbone + Cbeta anlges and dihedrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('backbone.ndx') as i:\n",
    "    i.readline()\n",
    "    bb = np.array([ int(j)-1 for j in \" \".join(i.readlines()).split() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone angles and dihedrals\n",
    "#angles = np.array([ bb[i:i+3] for i in range(0,len(bb)-3) ])\n",
    "diheds = np.array([ bb[i:i+4] for i in range(0,len(bb)-4) ])\n",
    "diheds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX: select alpha carbons and matching betas\n",
    "tr1 = md.load(conf)\n",
    "cas = tr1.topology.select('name CA and not resname GLY')\n",
    "cbs = tr1.topology.select('name CB')\n",
    "assert(len(cas) == len(cbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices of CAs (non-GLY) on the backbone\n",
    "cai = np.argwhere(bb.reshape(1,-1) == cas.reshape(-1,1))[:,1]\n",
    "cai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# angles of CB-CA-X, where X is the next atom on the backbone\n",
    "cbangles = np.array([[ cbs[0], cas[0], bb[cai[0]+1] ]] +\n",
    "                   [[cbs[i], bb[cai[i]], bb[cai[i]-1] ] for i in range(1,len(cbs))])\n",
    "# just check \n",
    "cbangles+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbdiheds = np.array([[ cbs[0], cas[0], bb[cai[0]+1], bb[cai[0]+2] ]] +\n",
    "                   [[cbs[i], bb[cai[i]], bb[cai[i]-1], bb[cai[i]-2]] for i in range(1,len(cbs))])\n",
    "cbdiheds+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# just angles\n",
    "mol=asmsa.Molecule(pdb=conf,n_atoms=geoms[0].shape[0],\n",
    "                   angles=np.concatenate((angles,cbangles)),\n",
    "                   diheds=np.concatenate((diheds,cbdiheds)))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# molecule model with explicit angles and dihedrals, and sparse distances from among Calpha and Cbetas\n",
    "# (don't bother with distances now)\n",
    "sparse_dists = asmsa.NBDistancesSparse(geoms[0].shape[0], density=nb_density, atoms = np.concatenate((cas,cbs)))\n",
    "mol=asmsa.Molecule(pdb=conf,n_atoms=geoms[0].shape[0],\n",
    "                   angles=np.concatenate((angles,cbangles)),\n",
    "                   diheds=np.concatenate((diheds,cbdiheds)),\n",
    "                   fms=[sparse_dists]) \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_dists = asmsa.NBDistancesSparse(geoms[0].shape[0], density=nb_density, atoms = np.concatenate((cas,cbs)))\n",
    "dense_dists = asmsa.NBDistancesDense(geoms[0].shape[0])\n",
    "\n",
    "\n",
    "mol=asmsa.Molecule(pdb=conf,n_atoms=geoms[0].shape[0],\n",
    "                   diheds=np.concatenate((diheds,cbdiheds)),\n",
    "                   fms=[sparse_dists]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_model = mol.get_model()\n",
    "\n",
    "example_input = torch.randn((*geoms[0].shape[:2],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_model.angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_model.get_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sparse_dists.bonds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dense_dists.bonds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "##### Save the features (molecule) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_model = mol.get_model()\n",
    "\n",
    "example_input = torch.randn((*geoms[0].shape[:2],1))\n",
    "traced_script_module = torch.jit.trace(mol_model, example_input)\n",
    "\n",
    "traced_script_module.save('features.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "##### Compute the interanal coordinates now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "intcoords = [ mol.intcoord(g).T for g in geoms]\n",
    "print(\n",
    "    [ g.shape for g in geoms ],\n",
    "    [ i.shape for i in intcoords ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "[train,validate,test] = intcoords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "geoms[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = mol_model.dihed4_model(torch.from_numpy(geoms[2])).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, geoms):\n",
    "#        geoms = input.reshape(self.n_atoms, 3, -1)\n",
    "    a12 = geoms[self.atoms[:, 1]] - geoms[self.atoms[:, 0]]\n",
    "    a23 = geoms[self.atoms[:, 2]] - geoms[self.atoms[:, 1]]\n",
    "    a34 = geoms[self.atoms[:, 3]] - geoms[self.atoms[:, 2]]\n",
    "\n",
    "#        a12 = torch.nn.functional.normalize(a12, p=2, dim=1)\n",
    "#        a23 = torch.nn.functional.normalize(a23, p=2, dim=1)\n",
    "#        a34 = torch.nn.functional.normalize(a34, p=2, dim=1)\n",
    "\n",
    "    vp1 = torch.nn.functional.normalize(torch.cross(a12,a23,axis=1))\n",
    "    vp2 = torch.nn.functional.normalize(torch.cross(a23,a34,axis=1))\n",
    "    vp3 = torch.nn.functional.normalize(torch.cross(vp1,a23,axis=1))\n",
    "\n",
    "    sp1 = torch.sum(vp1 * vp2, axis=1)\n",
    "    sp2 = torch.sum(vp3 * vp2, axis=1)\n",
    "\n",
    "    \"\"\" original:\n",
    "    # output for i-th dihedral angle\n",
    "        aa = np.arctan2(sp1,sp2) - np.pi * .5\n",
    "        return np.sin(aa), np.cos(aa)\n",
    "    \"\"\"\n",
    "\n",
    "    #NOTE: Why adding two variables that determine each other? It the angle better?\n",
    "    # return torch.nn.functional.normalize(torch.stack([-sp2, sp1]), p=2, dim=0).reshape(2*len(self.atoms), geoms.shape[2])\n",
    "    return sp1,sp2\n",
    "    #return torch.stack([-sp2, sp1]).reshape(2*len(self.atoms), geoms.shape[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1,sp2 = forward(mol_model.dihed4_model,torch.from_numpy(geoms[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1.shape,sp2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack([-sp2, sp1]).reshape((146,-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = torch.from_numpy(np.array([[1,2,3],[4,5,6]]))\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = a1+.2\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack([a1,a2]).reshape(4,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_from_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the saved model -- should yield nearly 0.\n",
    "\n",
    "test_from_model = mol_model(torch.from_numpy(geoms[2])).numpy()\n",
    "np.max(test - test_from_model.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize training set\n",
    "train_mean = np.mean(train,axis=0)\n",
    "train -= train_mean\n",
    "train_scale = np.std(train,axis=0)\n",
    "train /= train_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize test and validation sets\n",
    "test -= train_mean\n",
    "test /= train_scale\n",
    "validate -= train_mean\n",
    "validate /= train_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Old gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mol = asmsa.Molecule(conf,topol)\n",
    "\n",
    "# internal coordinates and sparse any-any atom distances (not restricted to bonds)\n",
    "# eventually, top (and index) can be left out to use sparse distances only\n",
    "\n",
    "sparse_dists = asmsa.NBDistancesSparse(geoms[0].shape[0], density=nb_density)\n",
    "mol=asmsa.Molecule(pdb=conf,top=topol,ndx=index,fms=[sparse_dists])\n",
    "\n",
    "# dense distances are feasible for very small (upto 5 residua) peptides only\n",
    "\n",
    "# dense_dists = asmsa.NBDistancesDense(geom.shape[0])\n",
    "# mol = asmsa.Molecule(pdb=conf,top=topol,ndx=index,fms=[dense_dists])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {},
   "source": [
    "#### Alternative: only backbone + Cbeta anlges and dihedrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('backbone.ndx') as i:\n",
    "    i.readline()\n",
    "    bb = np.array([ int(j)-1 for j in \" \".join(i.readlines()).split() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone angles and dihedrals\n",
    "angles = np.array([ bb[i:i+3] for i in range(0,len(bb)-3) ])\n",
    "diheds = np.array([ bb[i:i+4] for i in range(0,len(bb)-4) ])\n",
    "angles, diheds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX: select alpha carbons and matching betas\n",
    "tr1 = md.load(conf)\n",
    "cas = tr1.topology.select('name CA and not resname GLY')\n",
    "cbs = tr1.topology.select('name CB')\n",
    "assert(len(cas) == len(cbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices of CAs (non-GLY) on the backbone\n",
    "cai = np.argwhere(bb.reshape(1,-1) == cas.reshape(-1,1))[:,1]\n",
    "cai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# angles of CB-CA-X, where X is the next atom on the backbone\n",
    "cbangles = np.array([[ cbs[0], cas[0], bb[cai[0]+1] ]] +\n",
    "                   [[cbs[i], bb[cai[i]], bb[cai[i]-1] ] for i in range(1,len(cbs))])\n",
    "# just check \n",
    "cbangles+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbdiheds = np.array([[ cbs[0], cas[0], bb[cai[0]+1], bb[cai[0]+2] ]] +\n",
    "                   [[cbs[i], bb[cai[i]], bb[cai[i]-1], bb[cai[i]-2]] for i in range(1,len(cbs))])\n",
    "cbdiheds+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just angles\n",
    "mol=asmsa.Molecule(pdb=conf,n_atoms=geoms[0].shape[0],\n",
    "                   angles=np.concatenate((angles,cbangles)),\n",
    "                   diheds=np.concatenate((diheds,cbdiheds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# molecule model with explicit angles and dihedrals, and sparse distances from among Calpha and Cbetas\n",
    "# (don't bother with distances now)\n",
    "sparse_dists = asmsa.NBDistancesSparse(geoms[0].shape[0], density=nb_density, atoms = np.concatenate((cas,cbs)))\n",
    "mol=asmsa.Molecule(pdb=conf,n_atoms=geoms[0].shape[0],\n",
    "                   angles=np.concatenate((angles,cbangles)),\n",
    "                   diheds=np.concatenate((diheds,cbdiheds)),\n",
    "                   fms=[sparse_dists]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_model = mol.get_model()\n",
    "\n",
    "example_input = torch.randn((*geoms[0].shape[:2],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_model.angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_model.get_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_dists.bonds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103",
   "metadata": {},
   "source": [
    "#### Save the features (molecule) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_model = mol.get_model()\n",
    "\n",
    "example_input = torch.randn((*geoms[0].shape[:2],1))\n",
    "traced_script_module = torch.jit.trace(mol_model, example_input)\n",
    "\n",
    "traced_script_module.save('features.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105",
   "metadata": {},
   "source": [
    "#### Compute the interanal coordinates now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "intcoords = [ mol.intcoord(g).T for g in geoms]\n",
    "print(\n",
    "    [ g.shape for g in geoms ],\n",
    "    [ i.shape for i in intcoords ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": [
    "[train,validate,test] = intcoords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the saved model -- should yield nearly 0.\n",
    "\n",
    "test_from_model = mol_model(torch.from_numpy(geoms[2])).numpy()\n",
    "np.max(test - test_from_model.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize training set\n",
    "train_mean = np.mean(train,axis=0)\n",
    "train -= train_mean\n",
    "train_scale = np.std(train,axis=0)\n",
    "train /= train_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize test and validation sets\n",
    "test -= train_mean\n",
    "test /= train_scale\n",
    "validate -= train_mean\n",
    "validate /= train_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111",
   "metadata": {},
   "source": [
    "## Save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save for usage in tune/train/test phase\n",
    "\n",
    "tf.data.Dataset.from_tensor_slices(train).save('datasets/intcoords/train')\n",
    "tf.data.Dataset.from_tensor_slices(validate).save('datasets/intcoords/validate')\n",
    "tf.data.Dataset.from_tensor_slices(test).save('datasets/intcoords/test')\n",
    "\n",
    "np.savetxt('datasets/intcoords/mean.txt',train_mean)\n",
    "np.savetxt('datasets/intcoords/scale.txt',train_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Density of the conformational space\n",
    "\n",
    "- Sample the training trajectory randomly\n",
    "- For each point in the trajectory:\n",
    "  - calculate RMSD to all points in the sample\n",
    "  - pick some number $n$ of nearest ones\n",
    "  - calculate the _density_ at this point as $$ d = \\sum_{i=1}^n e^{-d_i} / n $$  i.e. the nearer the sample points are, the higher the density\n",
    " \n",
    "Altogether, $d$ roughly corresponds to the probability that the molecule during simulation ends up in this area of the conformational space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 5000\n",
    "x_train = md.load('x_train.xtc', top=conf)\n",
    "tr_sample = x_train[np.random.choice(len(x_train),sample_size,False)]\n",
    "tr_sample.save('sample.xtc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmx.rms(f='x_train.xtc',f2='sample.xtc',s=conf,n='backbone.ndx',m='sample_rmsd.xpm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "rms = gf.XPM('sample_rmsd.xpm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "#### Visual check to verify the sample size is representative\n",
    "- typically, not many distances should be less than 0.1 nm and more than 1 nm \n",
    "(the latter depends on the molecule, can be more for e.g. big disordered proteins)\n",
    "- the histogram should be semi-smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rms.array.flatten(),bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_nearest = 200\n",
    "rms_sort = np.sort(rms.array.astype(np.float32))\n",
    "erms = np.exp(-rms_sort[:,:k_nearest])\n",
    "dens = (np.sum(erms,axis=1)-1.) / (erms.shape[1] - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120",
   "metadata": {},
   "source": [
    "#### Histogram of densities\n",
    "- quite high number of points should fall above 0.8, those are low energy basins\n",
    "- the interval [0.5, 1.0] should be reasonably covered\n",
    "- on the contrary, too many points below 0.4 would indicate either insufficient sampling above or too sparse trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dens,bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dens),len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('datasets/train_density.txt',dens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
