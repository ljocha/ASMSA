{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd trpcage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj as md\n",
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Input files\n",
    "\n",
    "All input files are prepared (up- or downloaded) in [prepare.ipynb](prepare.ipynb). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('inputs.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Save the model for Gromacs\n",
    "\n",
    "*Another wave of magics ...*\n",
    "\n",
    "There are multiple ways how atoms are numbered in PDB, GRO, etc. files. \n",
    "\n",
    "So far we worked with atoms numbered as in the `conf` PDB file, assuming `traj` XTC file was consistent with those.\n",
    "If the topology was used, it might have had different numbering, as Gromacs likes. \n",
    "\n",
    "In the subsequent simulations, we assume the usual protocol starting with `pdb2gmx` to generate topology,\n",
    "hence Gromacsish atom numbering will be followed afterwards.\n",
    "Therefore we need `plumed.dat` to pick the atoms according to the PDB file order, and skip hydrogens added by Gromacs. \n",
    "\n",
    "Many things can go wrong, therefore we strongly encorage to check the results manually. For example, the first residuum (ASP) of tryptophan cage may look like the following in PDB file:\n",
    "\n",
    "    ATOM      1  N   ASP     1      28.538  39.747  31.722  1.00  1.00           N\n",
    "    ATOM      2  CA  ASP     1      28.463  39.427  33.168  1.00  1.00           C\n",
    "    ATOM      3  C   ASP     1      29.059  37.987  33.422  1.00  1.00           C\n",
    "    ATOM      4  O   ASP     1      30.226  37.748  33.735  1.00  1.00           O\n",
    "    ATOM      5  CB  ASP     1      26.995  39.482  33.630  1.00  1.00           C\n",
    "    ATOM      6  CG  ASP     1      26.889  39.307  35.101  1.00  1.00           C\n",
    "    ATOM      7  OD1 ASP     1      27.749  39.962  35.773  1.00  1.00           O\n",
    "    ATOM      8  OD2 ASP     1      26.012  38.510  35.611  1.00  1.00           O\n",
    "    \n",
    "Which turns Gromacs topology: \n",
    "\n",
    "     1         N3      1    ASP      N      1     0.0782      14.01   ; qtot 0.0782\n",
    "     2          H      1    ASP     H1      2       0.22      1.008   ; qtot 0.2982\n",
    "     3          H      1    ASP     H2      3       0.22      1.008   ; qtot 0.5182\n",
    "     4          H      1    ASP     H3      4       0.22      1.008   ; qtot 0.7382\n",
    "     5         CT      1    ASP     CA      5     0.0292      12.01   ; qtot 0.7674\n",
    "     6         HP      1    ASP     HA      6     0.1141      1.008   ; qtot 0.8815\n",
    "     7         CT      1    ASP     CB      7    -0.0235      12.01   ; qtot 0.858\n",
    "     8         HC      1    ASP    HB1      8    -0.0169      1.008   ; qtot 0.8411\n",
    "     9         HC      1    ASP    HB2      9    -0.0169      1.008   ; qtot 0.8242\n",
    "    10          C      1    ASP     CG     10     0.8194      12.01   ; qtot 1.644\n",
    "    11         O2      1    ASP    OD1     11    -0.8084         16   ; qtot 0.8352\n",
    "    12         O2      1    ASP    OD2     12    -0.8084         16   ; qtot 0.0268\n",
    "    13          C      1    ASP      C     13     0.5621      12.01   ; qtot 0.5889\n",
    "    14          O      1    ASP      O     14    -0.5889         16   ; qtot 0\n",
    "    \n",
    "Besides adding hydrogens, the carboxyl group of the protein backbone (atoms 3,4 in PDB) is pushed down (to become 13,14 in the topology).\n",
    "\n",
    "Consequently, the ATOMS setting in the generated `plumed.dat` must be:\n",
    "\n",
    "    model: PYTORCH_MODEL_CV FILE=model.pt ATOMS=1,5,13,14,7,10,11,12, ...\n",
    "    \n",
    "i.e., the atoms are enumerated *in the order* of PDB file but *referring to numbers* of topology file. \n",
    "\n",
    "If there is any mismatch, the MD simulations are likely to fail, or at least to produce meaningless results.\n",
    "\n",
    "It's also **critical** that `{conf}`, `{top}`, and `{gro}` correspond to one another, and that `{gro}` **includes hydrogens**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_geom = np.moveaxis(np.stack(list(tf.data.Dataset.load('datasets/geoms/test'))),2,0)\n",
    "test_geom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_model = torch.jit.load('features.pt')\n",
    "torch_encoder = torch.jit.load('encoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.loadtxt('datasets/intcoords/mean.txt',dtype=np.float32)\n",
    "train_scale = np.loadtxt('datasets/intcoords/scale.txt',dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompleteModel(torch.nn.Module):\n",
    "    def __init__(self, mol_model, torch_encoder, train_mean, train_scale):\n",
    "        super(CompleteModel, self).__init__()\n",
    "        self.mol_model = mol_model\n",
    "        self.torch_encoder = torch_encoder\n",
    "        # Convert train_mean and train_scale from numpy to torch tensors\n",
    "        self.train_mean = torch.from_numpy(np.reshape(train_mean, (-1, 1)))\n",
    "        self.train_scale = torch.from_numpy(np.reshape(train_scale, (-1, 1)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # nice here, but plumed module provides us with a flat array (n_atoms*3,)\n",
    "        # mol_output = self.mol_model(x.moveaxis(0,-1))\n",
    "        mol_output = self.mol_model(x.reshape((-1,3,1)))\n",
    "        normalized = (mol_output - self.train_mean) / self.train_scale\n",
    "#        reshaped = normalized.reshape(-1)\n",
    "        #return self.torch_encoder(normalized.T)\n",
    "        # blbost, ale nepada: return x[:2]\n",
    "        lows = self.torch_encoder(normalized[:,0])\n",
    "        return lows\n",
    "\n",
    "# Initialize the CompleteModel class with your components\n",
    "complete_model = CompleteModel(mol_model, torch_encoder, train_mean, train_scale)\n",
    "\n",
    "# Save the Torch model using TorchScript trace\n",
    "# \n",
    "# same shape trick as in forward()\n",
    "# example_input = torch.randn([1,test_geom.shape[1], test_geom.shape[2]])\n",
    "example_input = torch.randn([1,test_geom.shape[1]*3])\n",
    "\n",
    "traced_script_module = torch.jit.trace(complete_model, example_input)\n",
    "\n",
    "model_file_name = \"model.pt\"\n",
    "traced_script_module.save(model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_geom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = mol_model(example_input.reshape((-1,3,1)))\n",
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = (f-np.reshape(train_mean,(-1,1)))/np.reshape(train_scale,(-1,1))\n",
    "n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch_encoder(n.T)\n",
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input.shape, example_input.reshape((-1,3,1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.jit.load('model.pt')\n",
    "lows = m(torch.tensor(test_geom)).numpy()\n",
    "lows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = md.load('x_test.xtc', top=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.xyz.shape, test_geom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "lows = m(torch.tensor(x.xyz)).numpy()\n",
    "lows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual check, should be the same as in train.ipynb\n",
    "rg = md.compute_rg(x)\n",
    "base = md.load(conf)\n",
    "rmsd = md.rmsd(x,base[0])\n",
    "cmap = plt.get_cmap('rainbow')\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.scatter(lows[:,0],lows[:,1],marker='.',c=rg,cmap=cmap)\n",
    "plt.colorbar(cmap=cmap)\n",
    "plt.title(\"Rg\")\n",
    "plt.subplot(122)\n",
    "plt.scatter(lows[:,0],lows[:,1],marker='.',c=rmsd,cmap=cmap)\n",
    "plt.colorbar(cmap=cmap)\n",
    "plt.title(\"RMSD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "#### Determine range of CVs for simulation\n",
    "\n",
    "Plumed maintains a grid to approximate accumulated bias potential, which size must be known in advance.\n",
    "\n",
    "Making it wider is safe, the simulation is less likely to escape and crash, but there is perfomance penalty.\n",
    "\n",
    "Calculate the CVs on the testset, determine their range, and add some margins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_margin = 3.  # that many times the actual computed size added on both sides\n",
    "\n",
    "lmin = np.min(lows,axis=0)\n",
    "lmax = np.max(lows,axis=0)\n",
    "llen = lmax-lmin\n",
    "lmin -= llen * grid_margin\n",
    "lmax += llen * grid_margin\n",
    "\n",
    "lmin, lmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atom numbering magic with Gromacs, see above\n",
    "\n",
    "grotr = md.load(gro)\n",
    "nhs = grotr.topology.select('element != H')\n",
    "\n",
    "with open(index) as f:\n",
    "    f.readline()\n",
    "    ndx = np.fromstring(\" \".join(f),dtype=np.int32,sep=' ')-1\n",
    "\n",
    "pdb2gmx = nhs[np.argsort(ndx)]+1\n",
    "\n",
    "# maybe double check manually wrt. the files\n",
    "pdb2gmx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"plumed.dat\",\"w\") as p:\n",
    "    p.write(f\"\"\"\\\n",
    "RESTART\n",
    "WHOLEMOLECULES ENTITY0=1-{grotr.xyz.shape[1]}\n",
    "model: PYTORCH_MODEL_CV FILE={model_file_name} ATOMS={','.join(map(str,pdb2gmx))}\n",
    "metad: METAD ARG=model.node-0,model.node-1 PACE=1000 HEIGHT=1 BIASFACTOR=15 SIGMA=0.1,0.1 GRID_MIN={lmin[0]},{lmin[1]} GRID_MAX={lmax[0]},{lmax[1]} FILE=HILLS\n",
    "PRINT FILE=COLVAR ARG=model.node-0,model.node-1,metad.bias STRIDE=100\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
