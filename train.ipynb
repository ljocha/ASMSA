{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# ASMSA: Train AAE model with the tuned hyperparameters\n",
    "\n",
    "**Previous steps**\n",
    "- [prepare.ipynb](prepare.ipynb): Download and sanity check input files\n",
    "- [tune.ipynb](tune.ipynb): Perform initial hyperparameter tuning for this molecule\n",
    "\n",
    "**Next step**\n",
    "- [md.ipynb](md.ipynb): Use a trained model in MD simulation with Gromacs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Notebook setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd trpcage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = 2\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS']=str(threads)\n",
    "import tensorflow as tf\n",
    "\n",
    "# PyTorch favours OMP_NUM_THREADS in environment\n",
    "import torch\n",
    "\n",
    "# Tensorflow needs explicit cofig calls\n",
    "tf.config.threading.set_inter_op_parallelism_threads(threads)\n",
    "tf.config.threading.set_intra_op_parallelism_threads(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asmsa.tuning_analyzer import TuningAnalyzer\n",
    "import tensorflow_probability as tfp\n",
    "import matplotlib.pyplot as plt\n",
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from tensorflow import keras\n",
    "import keras_tuner\n",
    "import asmsa.visualizer as visualizer\n",
    "import asmsa\n",
    "\n",
    "\n",
    "from asmsa.plot_training import LiveTrainingPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Input files\n",
    "\n",
    "All input files are prepared (up- or downloaded) in [prepare.ipynb](prepare.ipynb). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('inputs.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exec(open('inputs-des.py').read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Apply the tuning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick from plots in tune.ipynb\n",
    "\n",
    "best_enc_seed=32\n",
    "best_disc_seed=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get best HP from latest tuning\n",
    "analyzer = TuningAnalyzer()\n",
    "analyzer.get_best_hp(num_trials=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select HP to use by specifying trial_id\n",
    "#  e.g: trial_id = '483883b929b3445bff6dee9759c4d50ee3a4ba7f0db22e665c49b5f942d9693b'\n",
    "# ... or don't specify, by default use the trial with the lowest score\n",
    "trial_id = '6bfbaca34a9678b324d2407f7ecd4d14068133bad402441715220bfd5c299fca'\n",
    "\n",
    "hps = None\n",
    "for trial in analyzer.sorted_trials:\n",
    "    if trial['trial_id'] == trial_id:\n",
    "        hps = trial['hp']\n",
    "    \n",
    "if not hps:\n",
    "    print(f'Could not find trial with specified ID, using one with the lowest score - {analyzer.sorted_trials[0][\"trial_id\"]}')\n",
    "    hps = analyzer.sorted_trials[0]['hp']\n",
    "    \n",
    "print(hps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Load datasets\n",
    "Load filtered trajectory datasets that were processed in **prepare.ipynb**. Trajectories are in internal coordinates format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train dataset\n",
    "X_train = tf.data.Dataset.load('datasets/intcoords/train')\n",
    "\n",
    "# get batched version of dataset to feed to AAE model for training\n",
    "X_train_batched = X_train.batch(hps['batch_size'],drop_remainder=True)\n",
    "\n",
    "# get numpy version for visualization purposes\n",
    "X_train_np = np.stack(list(X_train))\n",
    "X_train_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test dataset\n",
    "X_test = tf.data.Dataset.load('datasets/intcoords/test')\n",
    "\n",
    "# get batched version of dataset to feed to AAE model for prediction\n",
    "X_test_batched = X_test.batch(hps['batch_size'],drop_remainder=True)\n",
    "\n",
    "# get numpy version for testing purposes\n",
    "X_test_np = np.stack(list(X_test))\n",
    "X_test_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = tf.data.Dataset.load('datasets/intcoords/validate').batch(hps['batch_size'],drop_remainder=True)\n",
    "X_val_np = np.stack(list(X_val))\n",
    "X_val_np.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Distribution prior\n",
    "Train with common prior distributions. See https://www.tensorflow.org/probability/api_docs/python/tfp/distributions for all available distributions. It is ideal to use tuned Hyperparameters for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set used prior\n",
    "\n",
    "# this one is (more or less) required to with the density alignment\n",
    "# prior = tfp.distributions.MultivariateNormalDiag(loc=[0.,0.])\n",
    "\n",
    "prior = tfp.distributions.Normal(loc=0, scale=1)\n",
    "# prior = tfp.distributions.Uniform()\n",
    "# prior = tfp.distributions.Weibull(1,0.5)\n",
    "# prior = tfp.distributions.Cauchy(loc=0, scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# prepare model using the best hyperparameters\n",
    "testm = asmsa.AAEModel((X_train_np.shape[1],),\n",
    "                       prior=prior,\n",
    "                       hp=hps,\n",
    "                       enc_seed=best_enc_seed,\n",
    "                       disc_seed=best_disc_seed,\n",
    "                       with_density=False\n",
    "                      )\n",
    "testm.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "testm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train it (can be repeated several times to add more epochs)\n",
    "\n",
    "metric_groups = {\n",
    "    'Autoencoder Loss': ['AE loss min', 'val_val_AE loss min'],\n",
    "    'Discriminator Loss': ['disc loss min', 'val_val_disc loss min']\n",
    "}\n",
    "\n",
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_val_AE loss min\",\n",
    "    min_delta=0.0001,\n",
    "    patience=15,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "testm.fit(X_train_batched, # X_train_dens, # X_train_batched,\n",
    "          epochs=1000,\n",
    "          verbose=2, # this flag is essential due to connection with EarlyStopping callback (epoch vs batch)\n",
    "          validation_data=X_val,\n",
    "          callbacks=[\n",
    "#              early_stop_cb,\n",
    "              LiveTrainingPlot(metric_groups=metric_groups, freq=1),\n",
    "              #visualizer.VisualizeCallback(testm,freq=25,inputs=X_train_np[15000:25000],figsize=(12,3))\n",
    "          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final visualization, pick a slice of the input data for demo purposes\n",
    "#visualizer.Visualizer(figsize=(12,3)).make_visualization(testm.call_enc(X_train_np[15000:20000]).numpy())\n",
    "\n",
    "# on test data\n",
    "visualizer.Visualizer(figsize=(12,3)).make_visualization(testm.call_enc(X_test_np).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer.Visualizer(figsize=(12,3)).make_visualization(testm.call_enc(X_train_np).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load testing trajectory for further visualizations and computations\n",
    "tr = md.load('x_train.xtc',top=conf)\n",
    "idx=tr[0].top.select(\"name CA\")\n",
    "\n",
    "# for trivial cases like Ala-Ala, where superposing on CAs fails\n",
    "#idx=tr[0].top.select(\"element != H\") \n",
    "\n",
    "tr.superpose(tr[0],atom_indices=idx)\n",
    "\n",
    "# reshuffle the geometry to get frame last so that we can use vectorized calculations\n",
    "geom = np.moveaxis(tr.xyz ,0,-1)\n",
    "geom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rgyr and rmsd color coded in low dim (rough view)\n",
    "\n",
    "lows = testm.call_enc(X_train_np).numpy()\n",
    "rg = md.compute_rg(tr)\n",
    "base = md.load(conf)\n",
    "rmsd = md.rmsd(tr,base[0])\n",
    "cmap = plt.get_cmap('rainbow')\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.scatter(lows[:,0],lows[:,1],marker='.',c=rg,cmap=cmap,s=1)\n",
    "plt.colorbar(cmap=cmap)\n",
    "plt.title(\"Rg\")\n",
    "plt.subplot(122)\n",
    "plt.scatter(lows[:,0],lows[:,1],marker='.',c=rmsd,cmap=cmap,s=1)\n",
    "plt.colorbar(cmap=cmap)\n",
    "plt.title(\"RMSD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Image prior\n",
    "\n",
    "**Almost surely broken now with the density alignment**\n",
    "\n",
    "Use Image as a prior distribution. Again use tuned Hyperparameters for better training performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://drive.google.com/uc?export=download&id=1I2WP92MMWS5s5vin_4cvmruuV-1W77Hl\", \"mushroom_bw.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmush = asmsa.AAEModel((X_train_np.shape[1],),\n",
    "                       hp=hps,\n",
    "                       enc_seed=best_enc_seed,\n",
    "                       disc_seed=best_disc_seed,\n",
    "                       prior='mushroom_bw.png'\n",
    "                      )\n",
    "mmush.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_val_AE loss min\",\n",
    "    min_delta=0.0001,\n",
    "    patience=15,\n",
    "    verbose=1,\n",
    "    mode=\"min\",\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "mmush.fit(X_train_batched, # X_train_dens, # X_train_batched,\n",
    "          epochs=1000,\n",
    "          verbose=2, # this flag is essential due to connection with EarlyStopping callback (epoch vs batch)\n",
    "          validation_data=X_val,\n",
    "          callbacks=[\n",
    "              early_stop_cb,\n",
    "              LiveTrainingPlot(metric_groups=metric_groups, freq=1),\n",
    "              #visualizer.VisualizeCallback(testm,freq=25,inputs=X_train_np[15000:25000],figsize=(12,3))\n",
    "          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "step=4\n",
    "tr2 = tr[::step]\n",
    "lows = mmush.call_enc(X_test_np[::step]).numpy()\n",
    "rg = md.compute_rg(tr2)\n",
    "base = md.load(conf)\n",
    "rmsd = md.rmsd(tr2,base[0])\n",
    "cmap = plt.get_cmap('rainbow')\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.scatter(lows[:,0],lows[:,1],marker='.',c=rg,cmap=cmap)\n",
    "plt.colorbar(cmap=cmap)\n",
    "plt.title(\"Rg\")\n",
    "plt.subplot(122)\n",
    "plt.scatter(lows[:,0],lows[:,1],marker='.',c=rmsd,cmap=cmap)\n",
    "plt.colorbar(cmap=cmap)\n",
    "plt.title(\"RMSD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Save the encoder and decoder models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "import onnx2torch\n",
    "import tempfile\n",
    "\n",
    "def _convert_to_onnx(model, destination_path):\n",
    "#    model = keras.models.load_model(source_path)\n",
    "\n",
    "    input_tensor = model.layers[0]._input_tensor\n",
    "#    input_tensor = model.inputs[0]\n",
    "    input_signature = tf.TensorSpec(\n",
    "        name=input_tensor.name, shape=input_tensor.shape, dtype=input_tensor.dtype\n",
    "    )\n",
    "    output_name = model.layers[-1].name\n",
    "\n",
    "    @tf.function(input_signature=[input_signature])\n",
    "    def _wrapped_model(input_data):\n",
    "        return {output_name: model(input_data)}\n",
    "\n",
    "    tf2onnx.convert.from_function(\n",
    "        _wrapped_model, input_signature=[input_signature], output_path=destination_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = testm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile() as onnx:\n",
    "    _convert_to_onnx(model.enc,onnx.name)\n",
    "    torch_enc = onnx2torch.convert(onnx.name)\n",
    "\n",
    "example_input = torch.randn([X_train_np.shape[1]])\n",
    "traced_script_module = torch.jit.trace(torch_enc, example_input)\n",
    "\n",
    "traced_script_module.save('encoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.enc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenc = torch.jit.load('encoder.pt')\n",
    "example_input = np.random.rand(10000,X_train_np.shape[1])\n",
    "rtf = model.enc(example_input)\n",
    "rpt = lenc(torch.tensor(example_input,dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxerr = np.max(np.abs(rtf - rpt.detach().numpy()))\n",
    "maxerr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.NamedTemporaryFile() as onnx:\n",
    "    _convert_to_onnx(model.dec,onnx.name)\n",
    "    torch_dec = onnx2torch.convert(onnx.name)\n",
    "\n",
    "example_input = torch.randn([2])\n",
    "traced_script_module = torch.jit.trace(torch_dec, example_input)\n",
    "\n",
    "traced_script_module.save('decoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "ldec = torch.jit.load('decoder.pt')\n",
    "example_input = np.random.rand(10000,2)\n",
    "rtf = model.dec(example_input)\n",
    "rpt = ldec(torch.tensor(example_input,dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = np.abs(rtf - rpt.detach().numpy())\n",
    "train_mean = np.loadtxt('datasets/intcoords/mean.txt',dtype=np.float32).reshape(1,1,-1)\n",
    "rerr = err/np.abs(train_mean)\n",
    "np.max(err),np.max(rerr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "# Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(open('inputs.py').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_geom = np.moveaxis(np.stack(list(tf.data.Dataset.load('datasets/geoms/test'))),2,0)\n",
    "test_geom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = md.load('trpcage_red.xtc', top='trpcage_correct.pdb')\n",
    "tr.xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "des = md.load('../DE-Shaw/trpcage_red.xtc', top='../DE-Shaw/trpcage_correct.pdb')\n",
    "des.xyz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.loadtxt('datasets/intcoords/mean.txt',dtype=np.float32)\n",
    "train_scale = np.loadtxt('datasets/intcoords/scale.txt',dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompleteModel(torch.nn.Module):\n",
    "    def __init__(self, mol_model, torch_encoder, train_mean, train_scale):\n",
    "        super(CompleteModel, self).__init__()\n",
    "        self.mol_model = mol_model\n",
    "        self.torch_encoder = torch_encoder\n",
    "        # Convert train_mean and train_scale from numpy to torch tensors\n",
    "        self.train_mean = torch.from_numpy(np.reshape(train_mean, (-1, 1)))\n",
    "        self.train_scale = torch.from_numpy(np.reshape(train_scale, (-1, 1)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mol_output = self.mol_model(x.moveaxis(0,-1))\n",
    "        normalized = (mol_output - self.train_mean) / self.train_scale\n",
    "#        reshaped = normalized.reshape(-1)\n",
    "        return self.torch_encoder(normalized.T)\n",
    "\n",
    "# Initialize the CompleteModel class with your components\n",
    "complete_model = CompleteModel(mol_model, torch_encoder, train_mean, train_scale)\n",
    "\n",
    "# Save the Torch model using TorchScript trace\n",
    "example_input = torch.randn([1,test_geom.shape[1], test_geom.shape[2]])\n",
    "traced_script_module = torch.jit.trace(complete_model, example_input)\n",
    "\n",
    "model_file_name = \"model.pt\"\n",
    "traced_script_module.save(model_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.jit.load('model.pt')\n",
    "lows = m(torch.tensor(tr.xyz)).numpy()\n",
    "np.savetxt(\"lows.txt\", lows)\n",
    "lows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual check, should be the same as in train.ipynb\n",
    "rg = md.compute_rg(tr)\n",
    "base = md.load(conf)\n",
    "rmsd = md.rmsd(tr,base[0])\n",
    "cmap = plt.get_cmap('rainbow')\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.scatter(lows[:,0],lows[:,1],marker='.',c=rg,cmap=cmap,s=1)\n",
    "plt.colorbar(cmap=cmap)\n",
    "plt.title(\"Rg\")\n",
    "plt.subplot(122)\n",
    "plt.scatter(lows[:,0],lows[:,1],marker='.',c=rmsd,cmap=cmap,s=1)\n",
    "plt.colorbar(cmap=cmap)\n",
    "plt.title(\"RMSD\")\n",
    "plt.savefig(\"Thermal-unfolding.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
